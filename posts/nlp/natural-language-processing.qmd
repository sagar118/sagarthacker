---
title: "What is Natural Language Processing?"
description: "A brief summary of what is natural language processing, it's challenges and applications."
author: "Sagar Thacker"
date: "2021-04-12"
categories: ["Natural Language Processing", "NLP"]
image: ../images/introduction-to-nlp/natural-language-processing.jpg
jupyter: python3
execute:
  eval: false
---

Natural language processing is a branch of Artificial Intelligence which aims to bridge the gap between how a computer and human communicate with each other. The two major handles used for communication are speech and written i.e. text.

## History of Natural Language Processing

The dawn of NLP can be dated back to the early 1900s. In 1950, Alan Turing published his famous article ["Computing Machinery and Intelligence"](https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence "Computing Machinery and Intelligence") which proposed what is now called the Turing test as a criterion of intelligence. It tests the ability of the computer program to impersonate a human in a real-time conversation with a human judge where the judge is unable to distinguish the human from the computer program. In 1954, the [Georgetown experiment](https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment "Georgetown Experiment") automatically translated more than sixty Russian words into English.

In 1957, Noam Chomsky’s Syntactic Structures a rule-based system of syntactic structures with ["universal grammar"](https://en.wikipedia.org/wiki/Universal_grammar "Universal Grammar") was an incredible advancement. Up to the 1980’s most of the NLP systems were based on complex hand-written rules but in the late 1980s by the introduction of machine learning algorithms for language processing revolutionized the field. A steady increase in computational power resulting from [Moore’s law](https://en.wikipedia.org/wiki/Moore%27s_law "Moore’s law") and use of statistical models that use probabilistic measures to map the features making up the input data. Watson an artificial intelligence software designed as a question answering system won the Jeopardy contest, defeating the best human players in February 2011.

Development of famous virtual assistants like Siri in 2011, Amazon Alexa in 2014, and Google Assistant in 2016. The use of deep learning produced better results than the state-of-the-art in many natural language processing tasks, such as machine translation, text classification, and many more. Recent advancements include the use of network architecture of the transformer which is based on the attention mechanism that has produced better results in various NLP tasks.

We humans in our daily life overlook the powerful ability of our human brain to read, understand the meaning of a word, it’s context (how does it relate to each other), understand humor, sarcasm, and thousand other things. How do we teach this to a computer?

## Challenges

**1. Ambiguity**: <br>
In a natural language, words are unique but their meaning may differ based on the context in which it is used. One classical example used is:
- The bank is a financial institution where customers can save or borrow money.
- Tom was sitting by the banks of the river.

In this example, we can see that the word “bank” is used in two different ways. The word is the same but the meaning is different. This is because the context in which the word is used is different.

**2. Co-Referencing**:<br>
It is a process to find all the phrases in the document that refer to the same entity. Example: Harry kept the paneer on the plate and ate it. Here it refers to the paneer that he ate which was kept on the plate.

**3. Information Extraction**:<br>
Identifying phrases in a language that refer to specific types of entities and relations in text. Named Entity Recognition (NER) is the task used to identify the names of people, organizations, places, etc, in a text.<br>
Example:<br>
Tom used to work at FedEx and lives in Mumbai, India.<br>
where Person = Tom, organization = FedEx and Place = Mumbai, India

**4. Personality, intention, emotions, and style**:<br>
Different authors may have different personalities, intentions, emotions, and styles to convey the same idea. Based on these factors the underlying idea can be interpreted in different ways. Use of humor or sarcasm may convey a meaning that is opposite of the literal one.

## Applications

**1. Machine Translation**: <br>
The idea behind machine translation is to develop a system that is capable of translating text from one language to another without any human intervention. Only translating the text from one language to another is not the key. Understanding the meaning behind the text and translating it to some other language is the crux of it.<br>
Example: Google Translate
    
**2. Automatic summarization**: <br>
We all love to read storybooks and always a good storybook will have a summary at the end that highlights the important things about the story. Likewise take any piece of text, a story, a news article, etc, and develop a system that can automatically summary the piece of text.<br>
Example: Inshorts – an app that summarizes each news article in 60 words.

**3. Sentiment Analysis**: <br>
It deals with the study of extracting opinions and sentiment that are not always explicitly expressed. For instance it helps the company to understand the level of consumer satisfaction for its goods and services.<br>
Example: “I love the new iPhone and it has a great camera.”.

Another branch of sentiment analysis is “Aspect based Sentiment Analysis” where it tries to extract opinions for each aspect from the customer review.<br>
Example: “The new iPhone is great it has a great camera but the battery life is not that good.” Here the customer is satisfied with the camera aspect of the iPhone but not the battery life.

**4. Text Classification**: <br>
Organizing text documents into predefined categories enables to classify the information or any activity.<br>
Examples: Classifying an email as spam or not spam.

**5. Question Answering**: <br>
Question answering deals with a system that can answer questions posed by humans in natural language. Sounds simple yet building the knowledge base, understanding the text, and to answer in natural language is altogether a thing in itself.

**6. Chatbots**: <br>
Chatbots are a piece of software that can simulate a conversation (or chat) with a user in natural language through websites, apps, messaging applications, etc. Chatbots are a natural evolution of question answering system but are one step further with their ability to understand the text and engage in a conversation.

**7. Speech Recognition**: <br>
Using our voice to interact with our phones has become a common phenomenon.<br>
For example to ask questions to our voice assistants like Google Assistant/Siri/Cortana, use of voice to type a piece of text.<br>
Recognizing speech has replaced the method by which we interact with our devices and made it so convenient.

Recent advancements in NLP have deepened our knowledge on how to tackle the various challenges in NLP. Also, this new decade will be filled with excitement and breakthroughs that awaits us. Stay tunned to deep dive into the world of NLP.

Share if you like it, comment if you loved it. Hope to see you guys in the next one. Peace! 
