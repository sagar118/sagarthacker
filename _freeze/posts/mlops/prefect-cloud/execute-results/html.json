{
  "hash": "e49a69f32befb621bc76be7567a319b7",
  "result": {
    "markdown": "---\ntitle: Prefect Cloud Deployment\ndescription: A comprehensive guide to deploying Prefect Flows on Prefect Cloud\nauthor: Sagar Thacker\ndate: '2023-06-16'\nimage: ./images/prefect-cloud/first-steps-ui.png\ncategories:\n  - MLOps\n  - Prefect\n  - Deployment\n  - Prefect-Cloud\nexecute:\n  echo: false\nformat:\n  html:\n    toc: true\n    code-summary: Show the code\n    code-line-numbers: true\n    code-block-background: true\n---\n\nPrefect Cloud is a hosted platform for managing your data workflows. That means you don't have to own your own servers. We know Prefect follows a hybrid approach, which means the storage of your flow and the execution environment (prefect server) are seperate from each other.\n\nWhy should this matter to you? Simply, it means you can run your code on your own infrastructure keeping the code and data on your own servers. Only the metadata about the run is sent to Prefect Cloud. This is a great way to keep your data secure.\n\nTo understand this better, let's look at it with an example. We'll follow through the following steps:\n\n1. Create a GitHub repo.\n2. Create a prefect project.\n3. Write a prefect flow, configure the yaml file, and push it to GitHub.\n4. Log into Prefect Cloud through CLI.\n5. Deploy the flow to Prefect Cloud.\n6. Create a worker and run the flow.\n7. [Optional] Run a mlflow experiment.\n\nIn our example, we'll store our code on GitHub and use the Prefect Cloud to record your runs. We'll start the prefect worker locally and run the flow locally. \n\nEverytime you run the deployed flow, the worker will clone the github repo and use the code to run the flow. All the metadata about the run will be sent to Prefect Cloud.\n\nLet's get started!\n\n## Deployment on Prefect Cloud\n\n### Step 1: Create a GitHub repo\n\nLogin to your GitHub account and create a new repository. Name it `prefect-cloud-demo` for instance. \n\nLocally, initialize a git repo and add the remote origin to your local repo.\n\n```bash\n# Initialize a git repo\ngit init\n# Add the remote origin to your local repo\ngit remote add origin [your-github-repo-url]\n```\n\n### Step 2: Setup\n\nIt is a good practice to create a virtual environment for each project. This helps us keep our dependencies separate and avoid any version conflicts.\n\n```{.bash filename=\"requirements.txt\"}\nfastparquet==2023.4.0\nmlflow==2.3.1\npandas==2.0.1\nprefect==2.10.8\nscikit_learn==1.2.2\nxgboost==1.7.5\npsycopg2-binary==2.9.5\n```\n\nLet's create a virtual environment named `venv` and install all the dependencies.\n\n```{.bash}\n# Create a virtual environment\nconda create -p venv python=3.10 -y\n\n# Activate the virtual environment\nconda activate venv/\n\n# Install all the dependencies\npip install -r requirements.txt --no-cache-dir\n```\n\n### Step 3: Create a prefect project\n\nCreate a prefect project using the CLI.\n    \n```bash \nprefect project init\n```\n\nThe folder structure of your project should look like this:\n\n```{.bash}\n.\n├── deployment.yaml\n├── prefect.yaml\n├── requirements.txt\n└── venv\n└── ./prefect (hidden)\n└── .prefectignore (hidden)\n```\n\n::: {.callout-note}\nOne thing to note here is that in the `prefect.yaml` file you'll see key named `pull` with a value for `git_clone_project`. It will contain the url of your GitHub repo. It automatically gets added when you run the `prefect project init` command in a git repo.\n\nEverytime you run a deployment flow it will pull the code from the repo to run it.\n:::\n\n### Step 3: Write a prefect flow, configure the yaml file, and push it to GitHub\n\nWe'll use the same flow we created in the previous section to keep things simple. \n\n```{.python filename=\"prefect_demo.py}\nfrom prefect import flow, task\n\n@task(name=\"say_hello\", log_prints=True)\ndef say_hello():\n    print(\"Hello, I'm a Task!\")\n\n@flow(name=\"mlflow-flow\", log_prints=True)\ndef flow_hello():\n    print(\"Hello, I'm a Flow!\")\n    print(\"I'm about to call a Task...\")\n    say_hello()\n\nif __name__ == \"__main__\":\n    flow_hello()\n```\n\nLet's now configure the `deployment.yaml` file. This file tells Prefect Cloud how to deploy your flow. \n\n```{.yaml filename=\"deployment.yaml\"}\ndeployments:\n- # base metadata\n  name: manual-deployment\n  tags: [\"test\"]\n  description: \"Trigger deployment using `run` CLI command or Prefect UI\"\n  \n  # flow-specific fields\n  entrypoint: prefect_demo.py:flow_hello\n  parameters:\n    name: \"Sagar\"\n  \n  # infra-specific fields\n  work_pool:\n    name: test-pool\n    work_queue_name: demo\n```\n\nLet's now push the code to GitHub.\n\n```{.bash}\n# Add all the files to git\ngit add .\n\n# Add .gitignore\ntouch .gitignore\n# Add the following to .gitignore file from https://github.com/github/gitignore/blob/main/Python.gitignore\n\n# Commit the changes\ngit commit -m \"Initial commit\"\n\n# Push the code to GitHub\ngit push -u origin main\n```\n\n### Step 4: Log into Prefect Cloud through CLI\n\nIf you haven't already created an account on Prefect Cloud, you can do so [here](https://app.prefect.cloud/auth/login). Enter your email and you'll receive a link to login to Prefect Cloud.\n\nNow, we'll create a workspace in Prefect Cloud. Workspaces are only available on prefect cloud. Workspaces offer the flexibility to organize and compartmentalize your workflows according to your preferences. \n\nFor instance, you can leverage separate workspaces to isolate development, staging, and production environments. They also provide a means to create clear boundaries between different teams, ensuring better organization and collaboration. \n\nCreate a workspace named `demo`.\n\nLet's go ahead and login to Prefect Cloud through CLI. Run the following command to see that which server you're connected to by default.\n\n```{.bash}\nprefect version\n```\n\nUnder the Server section, you'll notice Database as sqlite and SQLite version mentioned. This means when you run the flow, it will create a sqlite database on your local machine and store the metadata there.\n\n```{.bash}\nVersion:             2.10.8\nAPI version:         0.8.4\nPython version:      3.10.11\nGit commit:          79093235\nBuilt:               Mon, May 8, 2023 12:23 PM\nOS/Arch:             darwin/x86_64\nProfile:             default\nServer type:         ephemeral\nServer:\n  Database:          sqlite\n  SQLite version:    3.41.2\n```\n\nLet's now login to Prefect Cloud through CLI. Run the following command \n\n```{.bash}\nprefect cloud login\n```\n\n and you'll be presented with two options:\n\n1. Log in with a web browser.\n2. Paste an API key.\n\nLet's go ahead and login with a web browser. By default, option 1 will be highlighted and you can press enter to continue. This will open a browser window and you'll be asked to authorize.\n\nOnce you've authorized, you'll see a message like `Authenticated with Prefect Cloud! Using workspace '[email]/demo'`.\n\nNow if you run `prefect version`, you'll see that the server has changed to `cloud`. This means that when you run the flow, it will upload the metadata to Prefect Cloud.\n\n```{.bash}\nVersion:             2.10.8\nAPI version:         0.8.4\nPython version:      3.10.11\nGit commit:          79093235\nBuilt:               Mon, May 8, 2023 12:23 PM\nOS/Arch:             darwin/x86_64\nProfile:             default\nServer type:         cloud\n```\n\n### Step 5: Deploy the flow to Prefect Cloud\n\nBefore we deploy the flow, let's create a work pool. Follow the steps below:\n\n1. Go to the `Work Pools` tab on the left side of the screen.\n2. Click on the`+` icon on the top middle of the screen.\n3. Enter the name of the work pool as `test-pool`.\n4. Select the `Local Subprocess` as the Infrastructure Type.\n5. Click on the `Create` button.\n\nNow, let's deploy the flow to Prefect Cloud. Run the following command:\n\n```{.bash}\nprefect deploy --name manual-deployment\n```\n\n### Step 6: Run the deployed flow\n\nTo run the deployed flow, we need a `worker` that will run the flow. Run the following command to start a worker:\n\n```{.bash}\nprefect worker start -p test-pool\n```\n\nOpen a new terminal to run the flow. Now we have two options to run the deployed flow:\n\n1. Through CLI\n2. Through Prefect UI\n\nPreviously I have mostly used the Prefect UI to run the flow. But in this case, we'll use the CLI to run the flow. Run the following command to run the flow:\n\n```{.bash}\n# Command to run the flow\nprefect deployment run [DEPLOYMENT-NAME]\n\n# In our case, the command will be\nprefect deployment run  hello-flow/manual-deployment\n```\n\nIf you don't know the name of the deployment, you can run the following command to see all the deployments:\n\n```{.bash}\nprefect deployment ls\n```\n\nCongratulations 🎉🎉🎉! You've successfully deployed and run your first flow on Prefect Cloud.\n\nPrefect gives you the flexibility to store your code anywhere and run it anywhere. You can start the worker on local, EC2, or any other machine and run the flow.\n\nNow, let's see how to run the deployment with mlflow to record the metrics.\n\n## Run the deployment with mlflow [Optional]\n\nWe'll tweak the flow a little bit to record the metrics with mlflow. The code is super super simple, however, the main take away is how to set the tracking uri and start the mlflow server to track the metrics.\n\n```{.python filename=\"mlflow_demo.py\"}\nimport mlflow\nfrom prefect import flow, task\n\n@task(name=\"mlflow-run\", log_prints=True)\ndef mlflow_run():\n  with mlflow.start_run():\n    mlflow.log_metric(\"metric\", 1.0)\n\n@flow(name=\"mlflow-flow\", log_prints=True)\ndef flow_hello():\n    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n    mlflow.set_experiment(\"demo\")\n    \n    print(\"Hello, I'm a Flow!\")\n    print(\"I'm about to call a Task...\")\n    mlflow_run()\n\nif __name__ == \"__main__\":\n    flow_hello()\n```\n\nLet's now configure the `deployment.yaml` file. Add the following lines to the `deployment.yaml` file.\n\n```{.yaml filename=\"deployment.yaml\"}\n- # base metadata\n  name: mlflow-deployment\n  description: \"Trigger deployment using `run` CLI command or Prefect UI\"\n  \n  # flow-specific fields\n  entrypoint: mlflow_demo.py:flow_hello\n  \n  # infra-specific fields\n  work_pool:\n    name: test-pool\n    work_queue_name: mlflow-demo\n```\n\nLet's now push the code to GitHub.\n\n```{.bash}\n# Add all the files to git\ngit add .\n\n# Commit the changes\ngit commit -m \"Add mlflow demo\"\n\n# Push the code to GitHub\ngit push -u origin main\n```\n\nNow, we'll deploy the new flow to Prefect Cloud. Run the following command:\n\n```{.bash}\n# Deploy the flow\nprefect deploy --name mlflow-deployment\n\n# Checkout the deployment name\nprefect deployment ls\n```\n\nWe already have a worker running. However, if you don't have a worker running, you can start a worker by running the following command:\n\n```{.bash}\nprefect worker start -p test-pool\n```\n\nLet's start the mlflow server. Run the following command:\n\n```{.bash}\nmlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 127.0.0.1 --port 5000\n```\n\nNow, let's run the flow. Run the following command:\n\n```{.bash}\nprefect deployment run mlflow-flow/mlflow-deployment\n```\n\nSome pointer to note:\n\n- We set the tracking uri and experiment name in the function where the flow begins. \n    - This is important because if you set the tracking uri and experiment name in the `__main__` function, it will not work. \n    - When you run the flow, it runs the function where the flow begins. \n    - In our case, it's the `flow_hello` function.\n- We set the tracking uri to `http://127.0.0.1:5000` because we ran the server locally, however if you run the server on EC2 or any other machine, you need to set the tracking uri accordingly.\n- To start the mlflow server we used the backend store as `sqlite db` and `artifacts` directory to store the artifacts. \n- We also specified the host and post so as to map the mlflow server to the same port where we set the tracking uri.\n\nLastly, if you want to logout from the Prefect Cloud, run the following command:\n\n```{.bash}\nprefect cloud logout\n```\n\n## References\n\n- [Prefect Cloud Docs](https://docs.prefect.io/cloud/)\n- [Image Source](https://github.com/PrefectHQ/prefect/blob/main/docs/img/tutorial/first-steps-ui.png)\n\n## Conclusion\n\nIn this article, we learned how to deploy a flow to Prefect Cloud and run it. We also learned how to run the flow with mlflow to record the metrics.\n\nI hope you enjoyed this article. If you have any questions, feel free to reach out to me on [Twitter](https://twitter.com/sagarthacker118) or <a href=\"mailto:sagar+site@sagarthacker.com\">Email</a>.\n\n👏 Upvote if you liked it, 💬 comment if you loved it. Hope to see you guys in the next one. ✌️ Peace!\n\n",
    "supporting": [
      "prefect-cloud_files"
    ],
    "filters": [],
    "includes": {}
  }
}