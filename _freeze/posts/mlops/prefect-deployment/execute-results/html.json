{
  "hash": "e0f8994a46f86bb5d471f03033dfd083",
  "result": {
    "markdown": "---\ntitle: Prefect Deployment\ndescription: A comprehensive guide to deploying Prefect Flows\nauthor: Sagar Thacker\ndate: '2023-06-11'\nimage: ./images/prefect-deployment/flow-deployment-end-to-end.png\ncategories:\n  - MLOps\n  - Prefect\n  - Deployment\nexecute:\n  echo: false\nformat:\n  html:\n    toc: true\n    code-summary: Show the code\n    code-line-numbers: true\n    code-block-background: true\n---\n\nIn this post, we'll be looking at how to deploy a Prefect flow locally.\n\n## What does deployment mean?\n\nSo far, we've learned how to create and run a workflow on our local machine. The Prefect API has been helpful in tracking the workflow's status through the user interface.\n\nHowever, what if we need to run the workflow on a different machine or schedule it to run automatically? This is where deployment comes into play.\n\n## Deployment in Prefect\n\nTo deploy a Prefect workflow, we need to package the workflow code, settings, and infrastructure configuration. This packaging process enables us to manage the workflow using the Prefect API and execute it remotely on a Prefect agent. \n\nI understand this might sound technical, so let's simplify it further.\n\n- Deployment can be thought of as shipping a package that includes the workflow code, settings, and infrastructure configuration required by Prefect to run the workflow.\n- All the necessary files are packed into a single box and labeled with a yaml file e.g. `deployment.yaml`. This file contains information about the workflow, its location, and additional metadata.\n- Using the deployment.yaml file, we can ship the package to the Prefect API, which creates a deployment object and stores it in the Prefect database. The deployment is now ready to be executed.\n- However, simply deploying the workflow doesn't start its execution.\n- In Prefect, we have the concept of `work-pools` and `agents/workers`. When a deployed workflow runs, it creates a `flow run` which is similar to what we did previously when running a Prefect flow. \n- However, during deployment, the flow run is submitted to a specific work-pool for scheduling. Think of the work-pool as a staging area where the flow run waits to be picked up by an agent/worker. (Imagine package lying in the warehouse waiting for the courier to be picked).\n- An agent or worker (courier), operating within the execution environment, polls the work-pool for new runs to execute.\n- Once an agent/worker picks up a flow run, it proceeds to execute it and reports the status back to the Prefect API.\n\nIt might seem like a lot of steps, but it's quite simple once you get the hang of it. We'll be going through each step in detail in the next section.\n\n## Deployment in Action\n\nTo demonstrate deployment, we'll be using a simple prefect flow that has a flow with one task. The task simply prints a message to the console. You can find the code for the flow below.\n\n```{.python filename=\"prefect_demo.py}\nfrom prefect import flow, task\n\n@task(name=\"say_hello\", log_prints=True)\ndef say_hello():\n    print(\"Hello, I'm a Task!\")\n\n@flow(name=\"hello-flow\", log_prints=True)\ndef flow_hello():\n    print(\"Hello, I'm a Flow!\")\n    print(\"I'm about to call a Task...\")\n    say_hello()\n\nif __name__ == \"__main__\":\n    flow_hello()\n```\n\nThe flow is simple and will help us focus more on the deployment process rather than understanding what the flow does. Let's get started.\n\n### Step 1: Start a Prefect server\n\nBefore we can deploy our flow, we need to start a Prefect server. We'll be using the Prefect CLI command to start the server. Run the following command in your terminal.\n\n```{.bash}\nprefect server start\n```\n\n### Step 2: Create a yaml file for the deployment\n\nWe'll use the `prefect deployment build` command to create a deployment definition yaml file. Run the Prefect CLI command from the folder containing your flow script and any dependencies of the script.\n\n```{.bash}\nprefect deployment build [OPTIONS] PATH\n```\n\nPath to the flow is specified in the format `path-to-script:flow-function-name` — The path and filename of the flow script file, a colon, then the name of the **entrypoint** flow function.\n\nFor our example, the command will be:\n\n```{.bash}\nprefect deployment build -n flow_test -p default-agent-pool -q test prefect_demo.py:flow_hello\n```\n\nLet's break down the command:\n\n- `-n` specifies the name of the deployment. We've named our deployment `flow_test`.\n- `-p` specifies the name of the work-pool. Prefect provides a default work-pool named `default-agent-pool`.\n- `-q` specifies the name of the work queue. We've named our queue `test`.\n- `prefect_demo.py:flow_hello` specifies the path to the flow script, a colon, then the name of the flow function.\n\nWhen you run this command, Prefect:\n\n- Creates a flow_hello-deployment.yaml file for your deployment based on your flow code and options. Usually the format is `<flow_name>-deployment.yaml`. You can specify a different name using the `--output` option.\n- Uploads your flow files to the configured storage location (local by default). (We'll cover storage in a later post).\n- Submit your deployment to the work queue test. The work queue test will be created if it doesn't exist.\n\nYou can find the yaml file in the same folder as your flow script. \n\n### Work Queues\n\n<hr/>\n\nImagine work-pool has a big highway and work-queues are lanes on the highway. Each work-queue is a separate lane on the highway. When a flow run is submitted to a work-pool, it is placed in a work-queue. \n\nAs different lanes in a highway have different priorities, and purpose so do work-queues. For example, you might have a work-queue for high priority flows and another for low priority flows. You can seperate your test and production flows by using different work-queues.\n\nBelow you'll find a brief overview of work-queues and I highly recommend you read the [official documentation](https://docs.prefect.io/2.10.13/concepts/work-pools/#work-queues)\n\n- Work pools have a `default` queue where all work is sent by default, but additional queues can be added for finer control over work delivery.\n- Work queues have priorities indicated by unique positive integers, with lower numbers having higher priority. New queues can be added without affecting the priority of existing queues.\n- Work queues can also have their own concurrency limits, allowing for precise control over the execution of work. However, all queues are subject to the global work pool concurrency limit.\n\n### Step 3: Create a deployment on Prefect API\n\nNow that we have the deployment.yaml file, we can create a deployment on the Prefect API. To do this, we'll use the `prefect deployment apply` Prefect CLI command. \n\n```{.bash}\nprefect deployment apply PATH_TO_YAML_FILE\n```\n\nFor our example, the command will be:\n\n```{.bash}\nprefect deployment apply flow_hello-deployment.yaml\n```\n\nOnce the deployment is created, you'll see it in the CLI and the Prefect UI. Run the `prefect deployment ls` command to see a list of all deployments.\n\n```{.bash}\nprefect deployment ls\n```\n\n![](./images/prefect-deployment/cli-deploy.png)\n\n![](./images/prefect-deployment/ui-deploy.png)\n\nTo view the work-pool and work-queue in the Prefect UI, navigate to the `Work Pools` section and click on the `default-agent-pool` work-pool. Click on the `Work Queues` tab to view the `test` work-queue. You'll also notice a `default` work queue. This is the default work queue that Prefect creates when you create any work-pool.\n\n![](./images/prefect-deployment/ui-work-queue.png)\n\n### Step 4: Start an agent\n\nAgent processes are lightweight polling services that regularly check a work-pool for scheduled work and execute the corresponding flow runs.\n\nBy default, agents poll for work every 15 seconds. You can adjust this interval by configuring the `PREFECT_AGENT_QUERY_INTERVAL` setting in the [profile settings](https://docs.prefect.io/concepts/settings/).\n\nYou can have multiple agent processes running for a single work pool. Each agent process sends a unique ID to the server, which helps distinguish them from one another and informs users about the number of active agents.\n\nWe'll use the `prefect agent start` command to start an agent.\n\n```{.bash}\nprefect agent start -p [WORK_POOL_NAME]\n```\n\nFor our example, the command will be:\n\n```{.bash}\nprefect agent start -p default-agent-pool\n```\n\n### Step 5: Execute the deployment\n\nNow that we have an agent running, we can execute the deployment. To do this, we'll use the `prefect deployment run` command. \n\n```{.bash}\nprefect deployment run [OPTIONS] DEPLOYMENT_NAME\n```\n\nIf you don't know the name of the deployment, you can use the `prefect deployment ls` command to get a list of all deployments.\n\nFor our example, the command will be:\n\n```{.bash}\nprefect deployment run hello-flow/flow_test\n```\n\nAfter running the command, you'll see the flow run in the Prefect UI. Navigate to the `Flow Runs` section to view the flow run. Click on the flow run to view the logs.\n\n![](./images/prefect-deployment/ui-flow-run.png)\n\nYou can also run the flow from the Prefect UI from the `Flow` section. \n\n![](./images/prefect-deployment/ui-quick-run.png)\n\nCongratulations! You've successfully deployed and executed your first Prefect flow. Yet there's so much more to cover like schedules, storage, agents, workers, and more. \n\nCongratulations! 🎉 You've successfully deployed and executed your first Prefect flow. Yet there's so much more to cover like 📅 schedules, 📦 storage, 💪 agents, workers, and more. \n\n## `deployment.yaml` file\n\nThe YAML file for a deployment contains extra settings required to create the deployment on the server.\n\nA single flow can have multiple deployments created for it, each with different schedules, tags, and other configurations. \n\nTo achieve this, you can have multiple deployment YAML files referencing the same flow definition, each specifying distinct settings. The only rule is that each deployment must have a unique name.\n\n![](./images/prefect-deployment/deployment-flow.png)\n\nEach deployment is linked to a specific flow, but a flow can be referenced by multiple deployments.\n\nDeployments are uniquely identified based on the combination of the flow name and deployment name.\n\nThis allows you to execute a single flow with various parameters, on multiple schedules, and in different environments. It also enables you to run different versions of the same flow for testing or production purposes.\n\n## Schedules\n\nSchedules allow you to instruct the Prefect API to automatically generate new flow runs for you at regular intervals.\n\nYou can attach a schedule to any flow deployment. The Prefect Scheduler service regularly checks each deployment and generates new flow runs based on the schedule defined for that deployment.\n\nThere are four recommended ways to create a schedule for a deployment:\n\n- Use the Prefect UI\n- Use the cron, interval, or rrule flags with the CLI deployment build command\n- Use the schedule parameter with a Python deployment file\n- Manually edit the deployment YAML file's schedule section\n\nPrefect offers different types of schedules that cater to various needs and provide a high level of customization:\n\n1. **Cron**: This type is well-suited for users who have prior experience with cron and want to leverage its functionality.\n2. **Interval**: Ideal for deployments that require a consistent cadence of execution, irrespective of specific timestamps.\n3. **RRule**: Designed for deployments that rely on calendar-based logic, allowing for simple recurring schedules, irregular intervals, exclusions, or adjustments based on specific days of the month.\n\nThese schedule types offer flexibility and can accommodate a wide range of scheduling requirements.\n\nWe'll go through an example of scheduling a flow run in the [section](#scheduled-flow-run-example-with-worker) below.\n\n## Agents and Workers\n\nWork-pools serve as a way to organize work that agents or workers pick up for execution. The coordination between deployments and agents happens through a shared work-pool name.\n\nIn case you want to create a new work pool, you would have to choose the `type` of the work pool. `Type` defines the type of infrastructure that can execute runs from this work pool.\n\nThat's where which polling service (`Agent` / `Worker`) is decided. View the table below to understand the difference between the two.\n\n\n| Work-Pool Type                   | Agent/Worker | Description                                  |\n|---------------------------------|--------------|----------------------------------------------|\n| Amazon Elastic Container Service | Worker       | Executes flow runs as ECS tasks               |\n| Azure Container Service          | Worker       | Executes flow runs in ACI containers          |\n| Google Cloud Run                 | Worker       | Executes flow runs as Google Cloud Run jobs   |\n| Docker                           | Worker       | Executes flow runs within Docker containers   |\n| Kubernetes                       | Worker       | Executes flow runs as Kubernetes jobs         |\n| Process                          | Worker       | Executes flow runs in subprocesses            |\n| Prefect Agent                    | Agent        | Executes flow runs in subprocesses            |\n\nWe have seen an example of an agent in the previous [section](#step-4-start-an-agent). Let's look at an example of a worker.\n\n## Worker\n\n::: {.callout-warning}\nWorkers are a beta feature and are subject to change in future releases.\n:::\n\nWorkers are similar to Agents in that they are long-running processes that poll for work i.e., fetch scheduled runs from a work pool and carry out their execution.\n\nHowever, workers provide the advantage of more control over infrastructure configuration and the capability to route work to specific types of execution environments.\n\nEach worker is assigned a type that corresponds to the specific execution environment where it will submit flow runs. Workers can only join work pools that match their designated type. Consequently, when deployments are associated with a work pool, you can determine the execution environment in which scheduled flow runs for that deployment will be executed.\n\nAbove table shows the different types of workers available. Prefect also provides a way to create your own [worker type](https://docs.prefect.io/guides/deployment/developing-a-new-worker-type/).\n\n\n## Scheduled Flow Run Example with Worker\n\n### Step 1: Create a new work-pool.\n\n```{.bash}\nprefect work-pool create [OPTIONS] NAME\n```\n\nFor our example, the command will be:\n```{.bash}\nprefect work-pool create test-pool -t process\n```\n\n- `-t` or `--type` flag is used to specify the type of work-pool. In our case, we are using the `process` type.\n\nOn CLI you can use the command `prefect work-pool ls` to list all the work-pools.\n\n![](./images/prefect-deployment/cli-schedule-deploy.png)\n\n![](./images/prefect-deployment/ui-work-pool.png)\n\n### Step 2: Create a new yaml file.\n\n```{.bash}\nprefect deployment build -n demo_schedule -p test-pool -q demo --cron \"0 0 * * *\" --output demo_schedule.yaml prefect_demo.py:flow_hello\n```\n\n- `--cron` flag is used to specify the cron schedule.\n\nThis create flow runs for this deployment every day at midnight.\n\n### Step 3: Apply the deployment.\n\n```{.bash}\nprefect deployment apply demo_schedule.yaml\n```\n\n![](./images/prefect-deployment/ui-schedule-deploy.png)\n\n![](./images/prefect-deployment/ui-schedule-deploy-2.png)\n\n### Step 4: Start the worker.\n\n```{.bash}\nprefect worker start -p test-pool\n```\n\n### Step 5: Execute the deployment. \n\nEither run the deployment from the Prefect UI or use the CLI command.\n\n::: {.callout-note}\nOne observation you might have made is that we are using the same flow for both the deployments but with different deployments. This is because we want to run the first flow manually through CLI or UI and second on a schedule.\n:::\n\nFirst can be used to test the flow and second can be used to run the flow on a schedule. It completely depends on your use case.\n\nI hope this provides a comprehensive overview of Prefect deployment and steps to deploy a flow. Hush... there's an abundance yet to explore.\n\n## Storage\n\nPrefect follows a hybrid model where your flow code stays within your storage and execution infrastructure and never lives on the Prefect server or database. What does that mean?\n\nIt means that there's always a boundary between your code, your private infrastructure, and the Prefect backend. You can use your existing storage infrastructure to store your flow code. Prefect supports a wide range of storage options like GitHub, local storage, Bitbucket, Amazon S3, Google Cloud Storage, Azure Storage, and more.\n\nTill now we have been using local storage to store our flow code and run the Prefect Server. However, you might choose to store the flow code in a GitHub repository and run the Prefect Server on your local machine. Prefect supports this as well.\n\n![](./images/prefect-deployment/deployment-flow-storage.png)\n\nWhile creating a deployment, you can specify the storage location of your flow code. This let's Prefect Agent/Worker know where to look for the flow code.\n\nOne cool thing about it is if you make changes to your flow code, you don't have to create a new deployment. Prefect Agent/Worker will automatically pick up the changes and execute the flow with the new code.\n\n::: {.callout-warning}\nHowever, changes to the infrastructure code will require a new deployment. Such as entrypoint. This part of changing the infrastructure code is experimental for me, I have to try it out more to better understand it.\n:::\n\nThis post has been a long one. Hence, I have not covered storage in detail. You can refer to the official [Prefect documentation](https://docs.prefect.io/2.10.13/concepts/storage/) on this topic for more details. Hopefully, in the next post I will cover the remaining topics.\n\n\nWait, there is `ONE` more thing!\n\n## Prefect Projects\n\n::: {.callout-warning}\nProjects are a beta feature and are subject to change in future releases.\n:::\n\nPrefect Projects is a new feature that describe how to prepare one or more flow deployments. You can create a project using the Prefect CLI command `prefect project init`. \n\nI would encourage you to follow along in a new directory so as to seperate what we did so far from the project.\n\n```{.bash}\n# Create a new directory\nmkdir project\n\n# Change directory\ncd project\n\n# Create a new Prefect project\nprefect project init\n```\n\nOnce you run the command, three files and a directory will be created - `deployment.yaml`, `prefect.yaml`, `.prefectignore`, and `.prefect/` directory.\n\n- `deployment.yaml`: a YAML file describing base settings for deployments produced from this project\n- `prefect.yaml`: a YAML file describing procedural steps for preparing a deployment from this project, as well as instructions for preparing the execution environment for a deployment run\n- `.prefect/`: a hidden directory where Prefect will store workflow metadata\n- `.prefectignore`: a file that specifies files and directories to ignore when preparing a deployment\n\nBelow we'll go through an example of how to use Prefect Projects to create a deployment.\n\n![](./images/prefect-deployment/flow-deployment-end-to-end.png)\n\n### Step 1: Create a new project.\n\n```{.bash}\nprefect project init\n```\n\n### Step 2: Create a flow. \n\nWe'll be utilizing the same flow we created earlier but with some changes. The flow will take a name as an argument, which are called `parameters` to a flow in Prefect.\n\n```{.python filename=\"prefect_demo.py\"}\nimport argparse\nfrom prefect import flow, task\n\n@task(name=\"say_hello\", log_prints=True)\ndef say_hello():\n    print(\"Hello, I'm a Task!\")\n\n@flow(name=\"hello-flow\", log_prints=True)\ndef flow_hello(name: str):\n    print(f\"Hello {name}, I'm a Flow!\")\n    print(\"I'm about to call a Task...\")\n    say_hello()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", help=\"Your name\", default=\"World\")\n    args = parser.parse_args()    \n    \n    flow_hello(args.name)\n```\n\n### Step 3: Start the Prefect Server.\n\n```{.bash}\nprefect server start\n```\n\n### Step 4: Start the Prefect Worker.\n\n```{.bash}\nprefect worker start -p test-pool\n```\n\n### Step 5: Configure the deployment.yaml file.\n\nPreviously, we created seperated files for creating a deployment and executing it. \n\nHowever, with Prefect Projects, we can do both in a single file. The deployment.yaml file is used to configure the deployment. Let's look at the contents of the file.\n\n```{.yaml filename=\"deployment.yaml\"}\ndeployments:\n- # base metadata\n  name: manual-deployment\n  tags: [\"test\"]\n  description: \"Trigger deployment using `run` CLI command or Prefect UI\"\n  \n  # flow-specific fields\n  entrypoint: prefect_demo.py:flow_hello\n  parameters:\n    name: \"Sagar\"\n  \n  # infra-specific fields\n  work_pool:\n    name: test-pool\n    work_queue_name: demo\n\n- # base metadata\n  name: scheduled-deployment\n  tags: [\"dev\"]\n  description: \"Trigger deployment using a Schedule\"\n  schedule:\n    cron: 0 0 * * *\n    timezone: America/Chicago\n  \n  # flow-specific fields\n  entrypoint: prefect_demo.py:flow_hello\n  parameters:\n    name: \"World\"\n  \n  # infra-specific fields\n  work_pool:\n    name: test-pool\n    work_queue_name: demo\n```\n\n### Step 6: Deploy your flow.\n\nThis file has two deployment declarations, each referencing a same flow in the project but with different parameters and schedule. Each deployment declaration has a unique name field and can be deployed individually by using the `--name` flag when deploying.\n\n::: {.callout-tip}\nYou also have the freedom to deploy different flows in the same yaml file. Example, we already have one flow file called `prefect_demo.py`. We can create another flow file called `prefect_demo_2.py` and reference it in the deployment.yaml file. Give the appropriate entrypoint and parameters and you are good to go.\n:::\n\nThis method of declaring multiple deployments allows the configuration for all deployments within a project to be version controlled and deployed with a single command.\n\nYou can deploy a single deployment by using the `--name` flag.\n\n```{.bash}\nprefect deploy --name manual-deployment\n```\n\nYou can also deploy multiple deployments by providing multiple `--name` flags.\n\n```{.bash}\nprefect deploy --name manual-deployment --name scheduled-deployment\n```\n\nOr, you can deploy all the deployments by using the `--all` flag.\n\n```{.bash}\nprefect deploy --all\n```\n\nFor our example, we'll deploy both the deployments.\n\n```{.bash}\nprefect deploy --all\n```\n\nYou might have noticed that we are using the `prefect deploy` command instead of `prefect deployment` command. This is because while using Prefect Projects, `prefect deploy` command under the hood performs multiple steps like build, push, pull, and applies the deployment. You can read more about it [here](https://docs.prefect.io/2.10.13/concepts/projects/#deployment-mechanics).\n\n![](./images/prefect-deployment/cli-project-deploy.png)\n\n![](./images/prefect-deployment/ui-project-deploy.png)\n\n### Step 7: Execute the deployments.\n\nYou can execute a deployment either through the Prefect UI or using the CLI command.\n\n```{.bash}\n# Using the default parameters\nprefect deployment run hello-flow/manual-deployment\n\n# Using the custom parameters\nprefect deployment run hello-flow/manual-deployment --param name=\"Prefect\"\n```\n\nOutput of the CLI command with default parameters.\n\n![](./images/prefect-deployment/ui-project-run.png)\n\nOutput of the CLI command with custom parameters.\n\n![](./images/prefect-deployment/ui-project-run-custom.png)\n\nCongratulations! 🎉 You have successfully created your first Prefect Project. \n\nPrefect Project have a lot more to offer. \n\nI encourage you to read about [Templating Options](https://docs.prefect.io/2.10.13/concepts/projects/#templating-options) for `deployment.yaml` file that lets you refer dynamic value to the file. Also, read more about `prefect.yaml` file [here](https://docs.prefect.io/2.10.13/concepts/projects/#the-prefect-yaml-file).\n\n## References\n\n1. [Deployments](https://docs.prefect.io/2.10.13/concepts/deployments/)\n2. [Work Pools, Workers & Agents](https://docs.prefect.io/2.10.13/concepts/work-pools/)\n3. [Storage](https://docs.prefect.io/2.10.13/concepts/storage/)\n4. [Schedules](https://docs.prefect.io/2.10.13/concepts/schedules/)\n5. [Projects](https://docs.prefect.io/2.10.13/concepts/projects/)\n6. [Deployment Tutorial](https://docs.prefect.io/2.10.13/tutorial/deployments/)\n7. [End-to-End Example Image](https://github.com/PrefectHQ/prefect/blob/main/docs/img/concepts/flow-deployment-end-to-end.png)\n\n## Conclusion\n\nIn this post, we covered the basics of Prefect deployment and how to deploy a flow. We also covered Prefect Projects and how to use it to create a deployment. In the next post, we'll cover storgae and deployment on Prefect Cloud.\n\nThank you for reading and I hope you found this notebook helpful. 👏 Upvote if you liked it, 💬 comment if you loved it. Hope to see you guys in the next one. ✌️ Peace!\n\n",
    "supporting": [
      "prefect-deployment_files"
    ],
    "filters": [],
    "includes": {}
  }
}